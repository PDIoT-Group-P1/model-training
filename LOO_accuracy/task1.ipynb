{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:54:49.118737600Z",
     "start_time": "2023-11-20T22:54:47.588276Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Flatten, Dropout, Conv2D  ,MaxPooling2D, Reshape\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "respeck_filepaths = glob.glob(\"../Respeck/*\")\n",
    "df1 = pd.DataFrame()\n",
    "for rfp in respeck_filepaths:\n",
    "    files = glob.glob(f\"{rfp}/*\")\n",
    "    \n",
    "    for file in files:\n",
    "        [main_act,sub_act] = file.split(\".csv\")[0].split('_')[-2:]\n",
    "        # main_activity = file.split(\".csv\")[0].split('_')[-2]\n",
    "        \n",
    "        df = pd.read_csv(file,index_col=0)\n",
    "        df['activity'] = main_act\n",
    "        df['sub_activity'] = sub_act\n",
    "        df['user'] = rfp.split('\\\\')[-1]\n",
    "        # print(df)\n",
    "        df1 = pd.concat([df, df1], axis=0)\n",
    "\n",
    "df1 = df1[df1['sub_activity'] == 'breathingNormal']     \n",
    "df1.loc[df1['activity'].isin(('sitting', 'standing')),'activity'] = 'sitting_standing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['user','activity','timestamp', 'accel_x', 'accel_y', 'accel_z']\n",
    "# df1 = df1[columns]\n",
    "df_har = df1[columns]\n",
    "# removing null values\n",
    "df_har = df_har.dropna()\n",
    "df_har.shape\n",
    "# transforming the user to float\n",
    "df_har['user'] = df_har['user'].str.replace('s', '')\n",
    "df_har['user'] = df_har['user'].apply(lambda x:int(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_har.to_csv('task1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>accel_x</th>\n",
       "      <th>accel_y</th>\n",
       "      <th>accel_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing</td>\n",
       "      <td>1697605965</td>\n",
       "      <td>-0.080811</td>\n",
       "      <td>-1.003235</td>\n",
       "      <td>0.052429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing</td>\n",
       "      <td>1697606005</td>\n",
       "      <td>-0.069824</td>\n",
       "      <td>-0.988342</td>\n",
       "      <td>0.056091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing</td>\n",
       "      <td>1697606045</td>\n",
       "      <td>-0.076416</td>\n",
       "      <td>-0.987122</td>\n",
       "      <td>0.047546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing</td>\n",
       "      <td>1697606085</td>\n",
       "      <td>-0.082520</td>\n",
       "      <td>-0.985168</td>\n",
       "      <td>0.066345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing</td>\n",
       "      <td>1697606125</td>\n",
       "      <td>-0.074951</td>\n",
       "      <td>-0.996887</td>\n",
       "      <td>0.034607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639844</th>\n",
       "      <td>1</td>\n",
       "      <td>ascending</td>\n",
       "      <td>1697636165</td>\n",
       "      <td>0.108887</td>\n",
       "      <td>-0.771790</td>\n",
       "      <td>-0.042053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639845</th>\n",
       "      <td>1</td>\n",
       "      <td>ascending</td>\n",
       "      <td>1697636205</td>\n",
       "      <td>0.157715</td>\n",
       "      <td>-0.820862</td>\n",
       "      <td>-0.046448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639846</th>\n",
       "      <td>1</td>\n",
       "      <td>ascending</td>\n",
       "      <td>1697636245</td>\n",
       "      <td>0.174072</td>\n",
       "      <td>-0.888733</td>\n",
       "      <td>-0.058167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639847</th>\n",
       "      <td>1</td>\n",
       "      <td>ascending</td>\n",
       "      <td>1697636285</td>\n",
       "      <td>0.071289</td>\n",
       "      <td>-0.782043</td>\n",
       "      <td>0.091492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639848</th>\n",
       "      <td>1</td>\n",
       "      <td>ascending</td>\n",
       "      <td>1697636325</td>\n",
       "      <td>0.059326</td>\n",
       "      <td>-1.019592</td>\n",
       "      <td>-0.012268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>639849 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user          activity   timestamp   accel_x   accel_y   accel_z\n",
       "0         98  sitting_standing  1697605965 -0.080811 -1.003235  0.052429\n",
       "1         98  sitting_standing  1697606005 -0.069824 -0.988342  0.056091\n",
       "2         98  sitting_standing  1697606045 -0.076416 -0.987122  0.047546\n",
       "3         98  sitting_standing  1697606085 -0.082520 -0.985168  0.066345\n",
       "4         98  sitting_standing  1697606125 -0.074951 -0.996887  0.034607\n",
       "...      ...               ...         ...       ...       ...       ...\n",
       "639844     1         ascending  1697636165  0.108887 -0.771790 -0.042053\n",
       "639845     1         ascending  1697636205  0.157715 -0.820862 -0.046448\n",
       "639846     1         ascending  1697636245  0.174072 -0.888733 -0.058167\n",
       "639847     1         ascending  1697636285  0.071289 -0.782043  0.091492\n",
       "639848     1         ascending  1697636325  0.059326 -1.019592 -0.012268\n",
       "\n",
       "[639849 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ONLY RUN THIS AFTER CSV GENERATION\n",
    "general_act_df = pd.read_csv('task1.csv')\n",
    "general_act_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42   \n",
    "n_time_steps = 50 \n",
    "n_features = 3 \n",
    "step = 10\n",
    "n_epochs = 1      \n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEncoder:\n",
    "    def __init__(self):\n",
    "        print('hello')\n",
    "        self.class_mapping = {\n",
    "            'sitting_standing': [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            'lyingLeft':        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            'lyingRight':       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            'lyingBack':        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "            'lyingStomach':     [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "            'normalWalking':    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "            'running':          [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "            'descending':       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "            'ascending':        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "            'shuffleWalking':   [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "            'miscMovement':     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "        }\n",
    "\n",
    "    def fit_transform(self, y):\n",
    "        return np.array([self.class_mapping[cls] for cls in y])\n",
    "\n",
    "    def inverse_transform(self, y):\n",
    "        reverse_mapping = {v: k for k, v in self.class_mapping.items()}\n",
    "        return np.array([reverse_mapping[val] for val in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segments_no_overlap(data):\n",
    "    segments = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(0,  data.shape[0]- n_time_steps, step):  \n",
    "\n",
    "        xs = data['accel_x'].values[i: i + n_time_steps]\n",
    "\n",
    "        ys = data['accel_y'].values[i: i + n_time_steps]\n",
    "\n",
    "        zs = data['accel_z'].values[i: i + n_time_steps]\n",
    "\n",
    "        label = stats.mode(data['activity'][i: i + n_time_steps])[0][0]\n",
    "\n",
    "        segments.append([xs, ys, zs])\n",
    "\n",
    "        labels.append(label)\n",
    "        \n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, n_time_steps, n_features)\n",
    "    labels = np.asarray(labels).reshape(-1,1)\n",
    "    \n",
    "    # le = CustomLabelEncoder()\n",
    "    # labels = le.fit_transform(labels)\n",
    "    # return reshaped_segments,labels,le.class_mapping\n",
    "    return reshaped_segments, labels\n",
    "    # labels = np.asarray(pd.get_dummies(labels), dtype = np.float32)\n",
    "    # print(enc.categories_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_label(train_df,test_df):\n",
    "    # saving training and testing data\n",
    "    user = test_df['user'].unique()[0]\n",
    "    train_df.to_csv(f'./t1_train_test_data/train/{user}_train.csv')\n",
    "    test_df.to_csv(f'./t1_train_test_data/test/{user}_test.csv')\n",
    "    \n",
    "    # segmenting the data into windows \n",
    "    train_segments, train_labels = segments_no_overlap(train_df)\n",
    "    test_segments, test_labels = segments_no_overlap(test_df)\n",
    "    # transforming the labels into OneHotEncoding\n",
    "    enc = OneHotEncoder(handle_unknown='ignore').fit(train_labels)\n",
    "    train_labels_encoded = enc.transform(train_labels).toarray()\n",
    "    test_labels_encoded = enc.transform(test_labels).toarray()\n",
    "    \n",
    "    return train_segments, train_labels_encoded, test_segments, test_labels_encoded, enc.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_LSTM(X_train,y_train):\n",
    "    model = Sequential()\n",
    "    # RNN layer\n",
    "    model.add(LSTM(units = 128, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    # Dropout layer\n",
    "    model.add(Dropout(0.5)) \n",
    "    # Dense layer with ReLu\n",
    "    model.add(Dense(units = 64, activation='relu'))\n",
    "    # Softmax layer\n",
    "    model.add(Dense(y_train.shape[1], activation = 'softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cnn(trainX, trainy):\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((n_timesteps, n_features, 1)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,1), activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,1), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling2D(pool_size=(2,1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=n_epochs, batch_size=batch_size, verbose=1)\n",
    "    # evaluate model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1979/1979 [==============================] - 24s 12ms/step - loss: 0.4728 - accuracy: 0.8330\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.8341\n",
      "Test Accuracy (91): 0.834074079990387\n",
      "Test Loss (91): 0.4616837203502655\n"
     ]
    }
   ],
   "source": [
    "os.mkdir('./t1_train_test_data')\n",
    "os.mkdir('./t1_train_test_data/train')\n",
    "os.mkdir('./t1_train_test_data/test')\n",
    "accuracies = {}\n",
    "\n",
    "for user in general_act_df['user'].unique():\n",
    "    if user != 91:\n",
    "        continue\n",
    "    \n",
    "    train_df = general_act_df[general_act_df['user'] != user]\n",
    "    test_df = general_act_df[general_act_df['user'] == user]\n",
    "    \n",
    "    # save_train_test_data(user,train_df,test_df)\n",
    "\n",
    "    X_train, y_train, X_test, y_test, categories = get_segment_label(train_df,test_df)\n",
    "    \n",
    "    # model = model_LSTM(X_train,y_train)\n",
    "    # history = model.fit(X_train, y_train, epochs = n_epochs, validation_split = 0.20, batch_size = batch_size, verbose = 1)\n",
    "    \n",
    "    model  = model_cnn(X_train,y_train)\n",
    "    \n",
    "    loss, accuracy = model.evaluate(X_test, y_test, batch_size = batch_size, verbose = 1)\n",
    "    print(f\"Test Accuracy ({user}):\", accuracy)\n",
    "    print(f\"Test Loss ({user}):\", loss)\n",
    "    \n",
    "    accuracies[user] = {'loss':loss, 'accuracy': accuracy}\n",
    "    # break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_df = pd.DataFrame(accuracies)\n",
    "a_df.to_csv('./t1_train_test_data/t1_loo_accuracies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer_4 (QuantizeL  (None, 50, 3)            3         \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " quant_reshape_7 (QuantizeWr  (None, 50, 3, 1)         1         \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv2d_14 (QuantizeWr  (None, 48, 3, 64)        387       \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv2d_15 (QuantizeWr  (None, 46, 3, 64)        12483     \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_dropout_11 (QuantizeW  (None, 46, 3, 64)        1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_max_pooling2d_6 (Quan  (None, 23, 3, 64)        1         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " quant_flatten_11 (QuantizeW  (None, 4416)             1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_dense_22 (QuantizeWra  (None, 100)              441705    \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_23 (QuantizeWra  (None, 11)               1116      \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 455,698\n",
      "Trainable params: 455,419\n",
      "Non-trainable params: 279\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "q_aware_model = quantize_model(model)\n",
    "\n",
    "# `quantize_model` requires a recompile.\n",
    "q_aware_model.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, reshape_7_layer_call_fn, reshape_7_layer_call_and_return_conditional_losses, conv2d_14_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\chhal\\AppData\\Local\\Temp\\tmpruc2c2yz\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\chhal\\AppData\\Local\\Temp\\tmpruc2c2yz\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "quantized_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\chhal\\AppData\\Local\\Temp\\tmp7vr0w4hs\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\chhal\\AppData\\Local\\Temp\\tmp7vr0w4hs\\assets\n"
     ]
    }
   ],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open(f'../models/cnn_model_task{1}_{n_time_steps}_{n_features}.tflite', 'wb') as f:\n",
    "  f.write(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00304507 0.00304507 0.00710347 0.00780451 0.00304507 0.05904093\n",
      "  0.00304507 0.00304507 0.00304507 0.00304507 0.90473557]]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"../models/cnn_model_task1_50_3.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on one instance\n",
    "interpreter.set_tensor(input_details[0]['index'], np.float32(X_test[0:1]))\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.16427783902976847\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    interpreter.set_tensor(input_details[0]['index'], np.float32(X_test[i:i+1]))\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    total_predictions += 1\n",
    "    if np.argmax(output_data) == np.argmax(y_test[i]):\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sitting_standing' 'normalWalking' 'miscMovement' 'lyingStomach'\n",
      " 'lyingRight' 'lyingLeft' 'lyingBack' 'ascending']\n"
     ]
    }
   ],
   "source": [
    "t91 = pd.read_csv('./t1_data/test/91_test.csv')\n",
    "print(t91['activity'].unique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdiot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
