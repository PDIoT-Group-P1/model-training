{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:54:49.118737600Z",
     "start_time": "2023-11-20T22:54:47.588276Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Flatten, Dropout, Conv2D  ,MaxPooling2D, Reshape\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27136\\1668605670.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# main_activity = file.split(\".csv\")[0].split('_')[-2]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'activity'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain_act\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sub_activity'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msub_act\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\chhal\\anaconda3\\envs\\pdiot\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\chhal\\anaconda3\\envs\\pdiot\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\chhal\\anaconda3\\envs\\pdiot\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\chhal\\anaconda3\\envs\\pdiot\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\chhal\\anaconda3\\envs\\pdiot\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\chhal\\anaconda3\\envs\\pdiot\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\chhal\\anaconda3\\envs\\pdiot\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\chhal\\anaconda3\\envs\\pdiot\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\chhal\\anaconda3\\envs\\pdiot\\lib\\codecs.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, errors)\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[0mbyte\u001b[0m \u001b[0msequences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m     \"\"\"\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'strict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[1;31m# undecoded input that is kept between calls to decode()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "respeck_filepaths = glob.glob(\"../Respeck/*\")\n",
    "df1 = pd.DataFrame()\n",
    "for rfp in respeck_filepaths:\n",
    "    files = glob.glob(f\"{rfp}/*\")\n",
    "    \n",
    "    for file in files:\n",
    "        [main_act,sub_act] = file.split(\".csv\")[0].split('_')[-2:]\n",
    "        # main_activity = file.split(\".csv\")[0].split('_')[-2]\n",
    "        \n",
    "        df = pd.read_csv(file,index_col=0)\n",
    "        df['activity'] = main_act\n",
    "        df['sub_activity'] = sub_act\n",
    "        df['user'] = rfp.split('\\\\')[-1]\n",
    "        # print(df)\n",
    "        df1 = pd.concat([df, df1], axis=0)\n",
    "\n",
    "df1 = df1[df1['sub_activity'] == 'breathingNormal']     \n",
    "df1.loc[df1['activity'].isin(('sitting', 'standing')),'activity'] = 'sitting_standing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['user','activity','timestamp', 'accel_x', 'accel_y', 'accel_z']\n",
    "# df1 = df1[columns]\n",
    "df_har = df1[columns]\n",
    "# removing null values\n",
    "df_har = df_har.dropna()\n",
    "df_har.shape\n",
    "# transforming the user to float\n",
    "df_har['user'] = df_har['user'].str.replace('s', '')\n",
    "df_har['user'] = df_har['user'].apply(lambda x:int(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_har.to_csv('task1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>accel_x</th>\n",
       "      <th>accel_y</th>\n",
       "      <th>accel_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ascending</td>\n",
       "      <td>1697605965</td>\n",
       "      <td>0.011963</td>\n",
       "      <td>-0.855774</td>\n",
       "      <td>-0.029846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ascending</td>\n",
       "      <td>1697606005</td>\n",
       "      <td>-0.001709</td>\n",
       "      <td>-0.826233</td>\n",
       "      <td>-0.036194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ascending</td>\n",
       "      <td>1697606045</td>\n",
       "      <td>-0.058838</td>\n",
       "      <td>-0.933899</td>\n",
       "      <td>-0.032532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ascending</td>\n",
       "      <td>1697606085</td>\n",
       "      <td>-0.002441</td>\n",
       "      <td>-1.115051</td>\n",
       "      <td>-0.028870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ascending</td>\n",
       "      <td>1697606125</td>\n",
       "      <td>-0.036621</td>\n",
       "      <td>-1.035217</td>\n",
       "      <td>-0.076477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639844</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing</td>\n",
       "      <td>1697636165</td>\n",
       "      <td>-0.057617</td>\n",
       "      <td>-0.985901</td>\n",
       "      <td>0.050232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639845</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing</td>\n",
       "      <td>1697636205</td>\n",
       "      <td>-0.061523</td>\n",
       "      <td>-0.980042</td>\n",
       "      <td>0.061951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639846</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing</td>\n",
       "      <td>1697636245</td>\n",
       "      <td>-0.067627</td>\n",
       "      <td>-1.000793</td>\n",
       "      <td>0.043396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639847</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing</td>\n",
       "      <td>1697636285</td>\n",
       "      <td>-0.057617</td>\n",
       "      <td>-0.976379</td>\n",
       "      <td>0.068054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639848</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing</td>\n",
       "      <td>1697636325</td>\n",
       "      <td>-0.056396</td>\n",
       "      <td>-0.978821</td>\n",
       "      <td>0.046814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>639849 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user          activity   timestamp   accel_x   accel_y   accel_z\n",
       "0          1         ascending  1697605965  0.011963 -0.855774 -0.029846\n",
       "1          1         ascending  1697606005 -0.001709 -0.826233 -0.036194\n",
       "2          1         ascending  1697606045 -0.058838 -0.933899 -0.032532\n",
       "3          1         ascending  1697606085 -0.002441 -1.115051 -0.028870\n",
       "4          1         ascending  1697606125 -0.036621 -1.035217 -0.076477\n",
       "...      ...               ...         ...       ...       ...       ...\n",
       "639844    98  sitting_standing  1697636165 -0.057617 -0.985901  0.050232\n",
       "639845    98  sitting_standing  1697636205 -0.061523 -0.980042  0.061951\n",
       "639846    98  sitting_standing  1697636245 -0.067627 -1.000793  0.043396\n",
       "639847    98  sitting_standing  1697636285 -0.057617 -0.976379  0.068054\n",
       "639848    98  sitting_standing  1697636325 -0.056396 -0.978821  0.046814\n",
       "\n",
       "[639849 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ONLY RUN THIS AFTER CSV GENERATION\n",
    "general_act_df = pd.read_csv('task1.csv')\n",
    "general_act_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42   \n",
    "n_time_steps = 50 \n",
    "n_features = 3 \n",
    "step = 10\n",
    "n_epochs = 1      \n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLabelEncoder:\n",
    "    def _init_(self):\n",
    "        self.class_mapping = {\n",
    "            'sitting_standing': 0,\n",
    "            'lyingLeft': 1,\n",
    "            'lyingRight': 2,\n",
    "            'lyingBack': 3,\n",
    "            'lyingStomach': 4,\n",
    "            'normalWalking': 5,\n",
    "            'running': 6,\n",
    "            'descending': 7,\n",
    "            'ascending': 8,\n",
    "            'shuffleWalking': 9,\n",
    "            'miscMovement':10\n",
    "        }\n",
    "\n",
    "    def fit_transform(self, y):\n",
    "        return [self.class_mapping[cls] for cls in y]\n",
    "\n",
    "    def inverse_transform(self, y):\n",
    "        reverse_mapping = {v: k for k, v in self.class_mapping.items()}\n",
    "        return [reverse_mapping[val] for val in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segments_overlap(data):\n",
    "    segments = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(0,  data.shape[0]- n_time_steps, step):  \n",
    "\n",
    "        xs = data['accel_x'].values[i: i + n_time_steps]\n",
    "\n",
    "        ys = data['accel_y'].values[i: i + n_time_steps]\n",
    "\n",
    "        zs = data['accel_z'].values[i: i + n_time_steps]\n",
    "\n",
    "        label = stats.mode(data['activity'][i: i + n_time_steps])[0][0]\n",
    "\n",
    "        segments.append([xs, ys, zs])\n",
    "\n",
    "        labels.append(label)\n",
    "        \n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, n_time_steps, n_features)\n",
    "    labels = np.asarray(labels).reshape(-1,1)\n",
    "\n",
    "    # le = LabelEncoder()\n",
    "    # labels = le.fit_transform(labels)\n",
    "    enc = OneHotEncoder(handle_unknown='ignore').fit(labels)\n",
    "    labels = enc.transform(labels).toarray()\n",
    "    # labels = np.asarray(pd.get_dummies(labels), dtype = np.float32)\n",
    "    # print(enc.categories_)\n",
    "    return reshaped_segments,labels,enc.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_LSTM(X_train,y_train):\n",
    "    model = Sequential()\n",
    "    # RNN layer\n",
    "    model.add(LSTM(units = 128, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    # Dropout layer\n",
    "    model.add(Dropout(0.5)) \n",
    "    # Dense layer with ReLu\n",
    "    model.add(Dense(units = 64, activation='relu'))\n",
    "    # Softmax layer\n",
    "    model.add(Dense(y_train.shape[1], activation = 'softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cnn(trainX, trainy):\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((n_timesteps, n_features, 1)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,1), activation='relu'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3,1), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling2D(pool_size=(2,1)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=n_epochs, batch_size=batch_size, verbose=1)\n",
    "    # evaluate model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_train_test_data(user,train_df,test_df):\n",
    "    train_df.to_csv(f'./t1_train_test_data/train/{user}_train.csv')\n",
    "    test_df.to_csv(f'./t1_train_test_data/test/{user}_test.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1971/1971 [==============================] - 26s 13ms/step - loss: 0.4818 - accuracy: 0.8305\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.1818 - accuracy: 0.9636\n",
      "Test Accuracy (1): 0.9636163115501404\n",
      "Test Loss (1): 0.18180325627326965\n"
     ]
    }
   ],
   "source": [
    "os.mkdir('./t1_train_test_data')\n",
    "os.mkdir('./t1_train_test_data/train')\n",
    "os.mkdir('./t1_train_test_data/test')\n",
    "accuracies = {}\n",
    "\n",
    "for user in general_act_df['user'].unique():\n",
    "    \n",
    "    train_df = general_act_df[general_act_df['user'] != user]\n",
    "    test_df = general_act_df[general_act_df['user'] == user]\n",
    "    \n",
    "    save_train_test_data(user,train_df,test_df)\n",
    "\n",
    "    X_train, y_train, categories = segments_overlap(train_df)\n",
    "    X_test, y_test, cat2 = segments_overlap(test_df)\n",
    "    \n",
    "    # model = model_LSTM(X_train,y_train)\n",
    "    # history = model.fit(X_train, y_train, epochs = n_epochs, validation_split = 0.20, batch_size = batch_size, verbose = 1)\n",
    "    \n",
    "    model  = model_cnn(X_train,y_train)\n",
    "    \n",
    "    loss, accuracy = model.evaluate(X_test, y_test, batch_size = batch_size, verbose = 1)\n",
    "    print(f\"Test Accuracy ({user}):\", accuracy)\n",
    "    print(f\"Test Loss ({user}):\", loss)\n",
    "    \n",
    "    accuracies[user] = {'loss':loss, 'accuracy': accuracy}\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_df = pd.DataFrame(accuracies)\n",
    "a_df.to_csv('./t1_train_test_data/t1_loo_accuracies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " quantize_layer_4 (QuantizeL  (None, 50, 3)            3         \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " quant_reshape_7 (QuantizeWr  (None, 50, 3, 1)         1         \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv2d_14 (QuantizeWr  (None, 48, 3, 64)        387       \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_conv2d_15 (QuantizeWr  (None, 46, 3, 64)        12483     \n",
      " apperV2)                                                        \n",
      "                                                                 \n",
      " quant_dropout_11 (QuantizeW  (None, 46, 3, 64)        1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_max_pooling2d_6 (Quan  (None, 23, 3, 64)        1         \n",
      " tizeWrapperV2)                                                  \n",
      "                                                                 \n",
      " quant_flatten_11 (QuantizeW  (None, 4416)             1         \n",
      " rapperV2)                                                       \n",
      "                                                                 \n",
      " quant_dense_22 (QuantizeWra  (None, 100)              441705    \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      " quant_dense_23 (QuantizeWra  (None, 11)               1116      \n",
      " pperV2)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 455,698\n",
      "Trainable params: 455,419\n",
      "Non-trainable params: 279\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "\n",
    "q_aware_model = quantize_model(model)\n",
    "\n",
    "# `quantize_model` requires a recompile.\n",
    "q_aware_model.compile(optimizer='sgd',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, reshape_7_layer_call_fn, reshape_7_layer_call_and_return_conditional_losses, conv2d_14_layer_call_fn, conv2d_14_layer_call_and_return_conditional_losses while saving (showing 5 of 17). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\chhal\\AppData\\Local\\Temp\\tmpruc2c2yz\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\chhal\\AppData\\Local\\Temp\\tmpruc2c2yz\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.target_spec.supported_types = [tf.float16]\n",
    "quantized_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\chhal\\AppData\\Local\\Temp\\tmp7vr0w4hs\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\chhal\\AppData\\Local\\Temp\\tmp7vr0w4hs\\assets\n"
     ]
    }
   ],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open(f'../models/cnn_model_task{1}_{n_time_steps}_{n_features}.tflite', 'wb') as f:\n",
    "  f.write(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00304507 0.00304507 0.00710347 0.00780451 0.00304507 0.05904093\n",
      "  0.00304507 0.00304507 0.00304507 0.00304507 0.90473557]]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"../models/cnn_model_task1_50_3.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on one instance\n",
    "interpreter.set_tensor(input_details[0]['index'], np.float32(X_test[0:1]))\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.16427783902976847\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    interpreter.set_tensor(input_details[0]['index'], np.float32(X_test[i:i+1]))\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    total_predictions += 1\n",
    "    if np.argmax(output_data) == np.argmax(y_test[i]):\n",
    "        correct_predictions += 1\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print('Test accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdiot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
