{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Flatten, Dropout, Conv2D  ,MaxPooling2D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "respeck_filepaths = glob.glob(\"../Respeck/*\")\n",
    "df1 = pd.DataFrame()\n",
    "for rfp in respeck_filepaths:\n",
    "    files = glob.glob(f\"{rfp}/*\")\n",
    "    \n",
    "    for file in files:\n",
    "        [main_act,sub_act] = file.split(\".csv\")[0].split('_')[-2:]\n",
    "        # main_activity = file.split(\".csv\")[0].split('_')[-2]\n",
    "        \n",
    "        df = pd.read_csv(file,index_col=0)\n",
    "        df['activity'] = main_act\n",
    "        df['sub_activity'] = sub_act\n",
    "        df['user'] = rfp.split('\\\\')[-1]\n",
    "        # print(df)\n",
    "        df1 = df1.append(df)\n",
    "\n",
    "df1 = df1[df1['sub_activity'] == 'breathingNormal']     \n",
    "df1.loc[df1['activity'].isin(('sitting', 'standing')),'activity'] = 'sitting_standing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['user','activity','timestamp', 'accel_x', 'accel_y', 'accel_z']\n",
    "# df1 = df1[columns]\n",
    "df_har = df1[columns]\n",
    "# removing null values\n",
    "df_har = df_har.dropna()\n",
    "df_har.shape\n",
    "# transforming the user to float\n",
    "df_har['user'] = df_har['user'].str.replace('s', '')\n",
    "df_har['user'] = df_har['user'].apply(lambda x:int(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_har.to_csv('task1.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>accel_x</th>\n",
       "      <th>accel_y</th>\n",
       "      <th>accel_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ascending</td>\n",
       "      <td>1697605965</td>\n",
       "      <td>0.011963</td>\n",
       "      <td>-0.855774</td>\n",
       "      <td>-0.029846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ascending</td>\n",
       "      <td>1697606005</td>\n",
       "      <td>-0.001709</td>\n",
       "      <td>-0.826233</td>\n",
       "      <td>-0.036194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>ascending</td>\n",
       "      <td>1697606045</td>\n",
       "      <td>-0.058838</td>\n",
       "      <td>-0.933899</td>\n",
       "      <td>-0.032532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>ascending</td>\n",
       "      <td>1697606085</td>\n",
       "      <td>-0.002441</td>\n",
       "      <td>-1.115051</td>\n",
       "      <td>-0.028870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ascending</td>\n",
       "      <td>1697606125</td>\n",
       "      <td>-0.036621</td>\n",
       "      <td>-1.035217</td>\n",
       "      <td>-0.076477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639844</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing</td>\n",
       "      <td>1697636165</td>\n",
       "      <td>-0.057617</td>\n",
       "      <td>-0.985901</td>\n",
       "      <td>0.050232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639845</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing</td>\n",
       "      <td>1697636205</td>\n",
       "      <td>-0.061523</td>\n",
       "      <td>-0.980042</td>\n",
       "      <td>0.061951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639846</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing</td>\n",
       "      <td>1697636245</td>\n",
       "      <td>-0.067627</td>\n",
       "      <td>-1.000793</td>\n",
       "      <td>0.043396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639847</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing</td>\n",
       "      <td>1697636285</td>\n",
       "      <td>-0.057617</td>\n",
       "      <td>-0.976379</td>\n",
       "      <td>0.068054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639848</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing</td>\n",
       "      <td>1697636325</td>\n",
       "      <td>-0.056396</td>\n",
       "      <td>-0.978821</td>\n",
       "      <td>0.046814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>639849 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user          activity   timestamp   accel_x   accel_y   accel_z\n",
       "0          1         ascending  1697605965  0.011963 -0.855774 -0.029846\n",
       "1          1         ascending  1697606005 -0.001709 -0.826233 -0.036194\n",
       "2          1         ascending  1697606045 -0.058838 -0.933899 -0.032532\n",
       "3          1         ascending  1697606085 -0.002441 -1.115051 -0.028870\n",
       "4          1         ascending  1697606125 -0.036621 -1.035217 -0.076477\n",
       "...      ...               ...         ...       ...       ...       ...\n",
       "639844    98  sitting_standing  1697636165 -0.057617 -0.985901  0.050232\n",
       "639845    98  sitting_standing  1697636205 -0.061523 -0.980042  0.061951\n",
       "639846    98  sitting_standing  1697636245 -0.067627 -1.000793  0.043396\n",
       "639847    98  sitting_standing  1697636285 -0.057617 -0.976379  0.068054\n",
       "639848    98  sitting_standing  1697636325 -0.056396 -0.978821  0.046814\n",
       "\n",
       "[639849 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ONLY RUN THIS AFTER CSV GENERATION\n",
    "general_act_df = pd.read_csv('task1.csv')\n",
    "general_act_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42   \n",
    "n_time_steps = 50 \n",
    "n_features = 3 \n",
    "step = 10\n",
    "n_epochs = 20      \n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segments_overlap(data):\n",
    "    segments = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(0,  data.shape[0]- n_time_steps, step):  \n",
    "\n",
    "        xs = data['accel_x'].values[i: i + n_time_steps]\n",
    "\n",
    "        ys = data['accel_y'].values[i: i + n_time_steps]\n",
    "\n",
    "        zs = data['accel_z'].values[i: i + n_time_steps]\n",
    "\n",
    "        label = stats.mode(data['activity'][i: i + n_time_steps])[0][0]\n",
    "\n",
    "        segments.append([xs, ys, zs])\n",
    "\n",
    "        labels.append(label)\n",
    "        \n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, n_time_steps, n_features)\n",
    "    labels = np.asarray(labels).reshape(-1,1)\n",
    "\n",
    "    enc = OneHotEncoder(handle_unknown='ignore').fit(labels)\n",
    "    labels = enc.transform(labels).toarray()\n",
    "    # labels = np.asarray(pd.get_dummies(labels), dtype = np.float32)\n",
    "    # print(enc.categories_)\n",
    "    return reshaped_segments,labels,enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segments_no_overlap(data):\n",
    "    segments= []\n",
    "    labels = []\n",
    "    \n",
    "    activities = data['activity'].unique()\n",
    "    for act in activities:\n",
    "        act_data = data[data['activity'] == act]\n",
    "        \n",
    "        # for i in range(0, len(all_data) - n_time_steps, step):\n",
    "        for i in range(0,  act_data.shape[0]- n_time_steps, step):  \n",
    "\n",
    "            xs = act_data['accel_x'].values[i: i + n_time_steps]\n",
    "            ys = act_data['accel_y'].values[i: i + n_time_steps]\n",
    "            zs = act_data['accel_z'].values[i: i + n_time_steps]\n",
    "\n",
    "            segments.append([xs, ys, zs])\n",
    "            labels.append(act)\n",
    "\n",
    "    #reshape the segments which is (list of arrays) to a list\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, n_time_steps, n_features)\n",
    "\n",
    "    labels = np.asarray(pd.get_dummies(labels), dtype = np.float32)\n",
    "    \n",
    "    return reshaped_segments,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def test_train_split(seg,labls):    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(seg, labls, test_size = 0.2, random_state = random_seed)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_LSTM(X_train,y_train):\n",
    "    model = Sequential()\n",
    "    # RNN layer\n",
    "    model.add(LSTM(units = 128, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    # Dropout layer\n",
    "    model.add(Dropout(0.5)) \n",
    "    # Dense layer with ReLu\n",
    "    model.add(Dense(units = 64, activation='relu'))\n",
    "    # Softmax layer\n",
    "    model.add(Dense(y_train.shape[1], activation = 'softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cnn(trainX, trainy):\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=n_epochs, batch_size=batch_size, verbose=1)\n",
    "    # evaluate model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1971/1971 [==============================] - 17s 8ms/step - loss: 0.5012 - accuracy: 0.8250\n",
      "Epoch 2/20\n",
      "1971/1971 [==============================] - 14s 7ms/step - loss: 0.2771 - accuracy: 0.9045\n",
      "Epoch 3/20\n",
      "1971/1971 [==============================] - 13s 7ms/step - loss: 0.2167 - accuracy: 0.9261\n",
      "Epoch 4/20\n",
      "1971/1971 [==============================] - 13s 7ms/step - loss: 0.1797 - accuracy: 0.9394\n",
      "Epoch 5/20\n",
      "1971/1971 [==============================] - 13s 7ms/step - loss: 0.1512 - accuracy: 0.9484\n",
      "Epoch 6/20\n",
      "1971/1971 [==============================] - 13s 7ms/step - loss: 0.1368 - accuracy: 0.9529\n",
      "Epoch 7/20\n",
      "1971/1971 [==============================] - 13s 7ms/step - loss: 0.1191 - accuracy: 0.9591\n",
      "Epoch 8/20\n",
      "1971/1971 [==============================] - 13s 7ms/step - loss: 0.1105 - accuracy: 0.9621\n",
      "Epoch 9/20\n",
      "1971/1971 [==============================] - 14s 7ms/step - loss: 0.1026 - accuracy: 0.9654\n",
      "Epoch 10/20\n",
      "1971/1971 [==============================] - 14s 7ms/step - loss: 0.0948 - accuracy: 0.9674\n",
      "Epoch 11/20\n",
      "1971/1971 [==============================] - 13s 7ms/step - loss: 0.0886 - accuracy: 0.9691\n",
      "Epoch 12/20\n",
      "1971/1971 [==============================] - 13s 7ms/step - loss: 0.0838 - accuracy: 0.9711\n",
      "Epoch 13/20\n",
      "1971/1971 [==============================] - 13s 7ms/step - loss: 0.0803 - accuracy: 0.9713\n",
      "Epoch 14/20\n",
      "1971/1971 [==============================] - 14s 7ms/step - loss: 0.0757 - accuracy: 0.9737\n",
      "Epoch 15/20\n",
      "1971/1971 [==============================] - 13s 7ms/step - loss: 0.0756 - accuracy: 0.9734\n",
      "Epoch 16/20\n",
      "1971/1971 [==============================] - 13s 6ms/step - loss: 0.0683 - accuracy: 0.9759\n",
      "Epoch 17/20\n",
      "1971/1971 [==============================] - 14s 7ms/step - loss: 0.0672 - accuracy: 0.9765\n",
      "Epoch 18/20\n",
      "1971/1971 [==============================] - 13s 7ms/step - loss: 0.0661 - accuracy: 0.9764\n",
      "Epoch 19/20\n",
      "1971/1971 [==============================] - 13s 7ms/step - loss: 0.0621 - accuracy: 0.9778\n",
      "Epoch 20/20\n",
      "1971/1971 [==============================] - 13s 7ms/step - loss: 0.0622 - accuracy: 0.9777\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0898 - accuracy: 0.9768\n",
      "Test Accuracy (1): 0.9768467545509338\n",
      "Test Loss (1): 0.08984408527612686\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "for user in general_act_df['user'].unique():\n",
    "    \n",
    "    train_df = general_act_df[general_act_df['user'] != user]\n",
    "    test_df = general_act_df[general_act_df['user'] == user]\n",
    "\n",
    "    X_train, y_train, categories = segments_overlap(train_df)\n",
    "    X_test, y_test, _ = segments_overlap(test_df)\n",
    "    \n",
    "    # model = model_LSTM(X_train,y_train)\n",
    "    # history = model.fit(X_train, y_train, epochs = n_epochs, validation_split = 0.20, batch_size = batch_size, verbose = 1)\n",
    "    model  = model_cnn(X_train,y_train)\n",
    "    \n",
    "    loss, accuracy = model.evaluate(X_test, y_test, batch_size = batch_size, verbose = 1)\n",
    "    print(f\"Test Accuracy ({user}):\", accuracy)\n",
    "    print(f\"Test Loss ({user}):\", loss)\n",
    "    \n",
    "    accuracies.append((user,loss,accuracy))\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\chhal\\AppData\\Local\\Temp\\tmp53g5sbhj\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\chhal\\AppData\\Local\\Temp\\tmp53g5sbhj\\assets\n"
     ]
    }
   ],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open(f'../models/cnn_model_task{1}_{n_time_steps}_{n_features}.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['ascending', 'descending', 'lyingBack', 'lyingLeft', 'lyingRight',\n",
       "        'lyingStomach', 'miscMovement', 'normalWalking', 'running',\n",
       "        'shuffleWalking', 'sitting_standing'], dtype='<U16')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdiot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
