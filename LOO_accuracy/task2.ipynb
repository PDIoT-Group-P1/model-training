{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Flatten, Dropout, Conv2D  ,MaxPooling2D\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "respeck_filepaths = glob.glob(\"../Respeck/*\")\n",
    "df1 = pd.DataFrame()\n",
    "for rfp in respeck_filepaths:\n",
    "    files = glob.glob(f\"{rfp}/*\")\n",
    "    \n",
    "    for file in files:\n",
    "        [main_act,sub_act] = file.split(\".csv\")[0].split('_')[-2:]\n",
    "        # main_activity = file.split(\".csv\")[0].split('_')[-2]\n",
    "        \n",
    "        df = pd.read_csv(file,index_col=0)\n",
    "        df['main_activity'] = main_act\n",
    "        df['sub_activity'] = sub_act\n",
    "        df['activity'] = \" \".join([main_act,sub_act])\n",
    "        df['user'] = rfp.split('\\\\')[-1]\n",
    "        # print(df)\n",
    "        df1 = df1.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['lyingBack breathingNormal', 'lyingBack coughing',\n",
       "       'lyingBack hyperventilating', 'lyingLeft breathingNormal',\n",
       "       'lyingLeft coughing', 'lyingLeft hyperventilating',\n",
       "       'lyingRight breathingNormal', 'lyingRight coughing',\n",
       "       'lyingRight hyperventilating', 'lyingStomach breathingNormal',\n",
       "       'lyingStomach coughing', 'lyingStomach hyperventilating',\n",
       "       'sitting_standing breathingNormal', 'sitting_standing coughing',\n",
       "       'sitting_standing hyperventilating'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = ['lyingBack breathingNormal', 'lyingBack coughing',\n",
    "       'lyingBack hyperventilating', 'lyingLeft breathingNormal',\n",
    "       'lyingLeft coughing', 'lyingLeft hyperventilating',\n",
    "       'lyingRight breathingNormal', 'lyingRight coughing',\n",
    "       'lyingRight hyperventilating', 'lyingStomach breathingNormal',\n",
    "       'lyingStomach coughing', 'lyingStomach hyperventilating',\n",
    "       'sitting breathingNormal', 'sitting coughing',\n",
    "       'sitting hyperventilating', 'standing breathingNormal',\n",
    "       'standing coughing', 'standing hyperventilating']\n",
    "\n",
    "\n",
    "df1 = df1[df1['activity'].isin(classes)]     \n",
    "df1.loc[df1['main_activity'].isin(('sitting', 'standing')),'main_activity'] = 'sitting_standing'\n",
    "\n",
    "df1['activity'] = df1[['main_activity', 'sub_activity']].agg(' '.join, axis=1) \n",
    "df1['activity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['user','activity','timestamp', 'accel_x', 'accel_y', 'accel_z']\n",
    "\n",
    "# df1 = df1[columns]\n",
    "df_har = df1[columns]\n",
    "# removing null values\n",
    "df_har = df_har.dropna()\n",
    "df_har.shape\n",
    "# transforming the user to float\n",
    "df_har['user'] = df_har['user'].str.replace('s', '')\n",
    "df_har['user'] = df_har['user'].apply(lambda x:int(x))\n",
    "df_har['activity'].unique().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['lyingBack breathingNormal', 'lyingBack coughing',\n",
       "       'lyingBack hyperventilating', 'lyingLeft breathingNormal',\n",
       "       'lyingLeft coughing', 'lyingLeft hyperventilating',\n",
       "       'lyingRight breathingNormal', 'lyingRight coughing',\n",
       "       'lyingRight hyperventilating', 'lyingStomach breathingNormal',\n",
       "       'lyingStomach coughing', 'lyingStomach hyperventilating',\n",
       "       'sitting_standing breathingNormal', 'sitting_standing coughing',\n",
       "       'sitting_standing hyperventilating'], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_har['activity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_har.to_csv('task2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>accel_x</th>\n",
       "      <th>accel_y</th>\n",
       "      <th>accel_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>lyingBack breathingNormal</td>\n",
       "      <td>1697605965</td>\n",
       "      <td>-0.596436</td>\n",
       "      <td>-0.181213</td>\n",
       "      <td>0.870056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>lyingBack breathingNormal</td>\n",
       "      <td>1697606005</td>\n",
       "      <td>-0.593994</td>\n",
       "      <td>-0.189026</td>\n",
       "      <td>0.880310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>lyingBack breathingNormal</td>\n",
       "      <td>1697606045</td>\n",
       "      <td>-0.591064</td>\n",
       "      <td>-0.172668</td>\n",
       "      <td>0.883484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>lyingBack breathingNormal</td>\n",
       "      <td>1697606085</td>\n",
       "      <td>-0.580322</td>\n",
       "      <td>-0.176819</td>\n",
       "      <td>0.875671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>lyingBack breathingNormal</td>\n",
       "      <td>1697606125</td>\n",
       "      <td>-0.598145</td>\n",
       "      <td>-0.189758</td>\n",
       "      <td>0.882263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957994</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing hyperventilating</td>\n",
       "      <td>1697636165</td>\n",
       "      <td>-0.170898</td>\n",
       "      <td>-0.940979</td>\n",
       "      <td>0.119324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957995</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing hyperventilating</td>\n",
       "      <td>1697636205</td>\n",
       "      <td>-0.153809</td>\n",
       "      <td>-0.949524</td>\n",
       "      <td>0.121521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957996</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing hyperventilating</td>\n",
       "      <td>1697636245</td>\n",
       "      <td>-0.188965</td>\n",
       "      <td>-0.937073</td>\n",
       "      <td>0.094666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957997</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing hyperventilating</td>\n",
       "      <td>1697636285</td>\n",
       "      <td>-0.133789</td>\n",
       "      <td>-0.999573</td>\n",
       "      <td>0.073181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957998</th>\n",
       "      <td>98</td>\n",
       "      <td>sitting_standing hyperventilating</td>\n",
       "      <td>1697636325</td>\n",
       "      <td>-0.145996</td>\n",
       "      <td>-0.989807</td>\n",
       "      <td>0.065369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>957999 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user                           activity   timestamp   accel_x  \\\n",
       "0          1          lyingBack breathingNormal  1697605965 -0.596436   \n",
       "1          1          lyingBack breathingNormal  1697606005 -0.593994   \n",
       "2          1          lyingBack breathingNormal  1697606045 -0.591064   \n",
       "3          1          lyingBack breathingNormal  1697606085 -0.580322   \n",
       "4          1          lyingBack breathingNormal  1697606125 -0.598145   \n",
       "...      ...                                ...         ...       ...   \n",
       "957994    98  sitting_standing hyperventilating  1697636165 -0.170898   \n",
       "957995    98  sitting_standing hyperventilating  1697636205 -0.153809   \n",
       "957996    98  sitting_standing hyperventilating  1697636245 -0.188965   \n",
       "957997    98  sitting_standing hyperventilating  1697636285 -0.133789   \n",
       "957998    98  sitting_standing hyperventilating  1697636325 -0.145996   \n",
       "\n",
       "         accel_y   accel_z  \n",
       "0      -0.181213  0.870056  \n",
       "1      -0.189026  0.880310  \n",
       "2      -0.172668  0.883484  \n",
       "3      -0.176819  0.875671  \n",
       "4      -0.189758  0.882263  \n",
       "...          ...       ...  \n",
       "957994 -0.940979  0.119324  \n",
       "957995 -0.949524  0.121521  \n",
       "957996 -0.937073  0.094666  \n",
       "957997 -0.999573  0.073181  \n",
       "957998 -0.989807  0.065369  \n",
       "\n",
       "[957999 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ONLY RUN THIS AFTER CSV GENERATION\n",
    "stationary_respiratory_df = pd.read_csv('task2.csv')\n",
    "stationary_respiratory_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42   \n",
    "n_time_steps = 50 \n",
    "n_features = 3 \n",
    "step = 10 \n",
    "n_epochs = 20      \n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segments_overlap(data):\n",
    "    segments = []\n",
    "    labels = []\n",
    "\n",
    "    for i in range(0,  data.shape[0]- n_time_steps, step):  \n",
    "\n",
    "        xs = data['accel_x'].values[i: i + n_time_steps]\n",
    "\n",
    "        ys = data['accel_y'].values[i: i + n_time_steps]\n",
    "\n",
    "        zs = data['accel_z'].values[i: i + n_time_steps]\n",
    "\n",
    "        label = stats.mode(data['activity'][i: i + n_time_steps])[0][0]\n",
    "\n",
    "        segments.append([xs, ys, zs])\n",
    "\n",
    "        labels.append(label)\n",
    "        \n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, n_time_steps, n_features)\n",
    "    labels = np.asarray(labels).reshape(-1,1)\n",
    "\n",
    "    enc = OneHotEncoder(handle_unknown='ignore').fit(labels)\n",
    "    labels = enc.transform(labels).toarray()\n",
    "    # labels = np.asarray(pd.get_dummies(labels), dtype = np.float32)\n",
    "    # print(enc.categories_)\n",
    "    return reshaped_segments,labels,enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segments_no_overlap(data):\n",
    "    segments= []\n",
    "    labels = []\n",
    "    \n",
    "    activities = data['activity'].unique()\n",
    "    for act in activities:\n",
    "        act_data = data[data['activity'] == act]\n",
    "        \n",
    "        # for i in range(0, len(all_data) - n_time_steps, step):\n",
    "        for i in range(0,  act_data.shape[0]- n_time_steps, step):  \n",
    "\n",
    "            xs = act_data['accel_x'].values[i: i + n_time_steps]\n",
    "            ys = act_data['accel_y'].values[i: i + n_time_steps]\n",
    "            zs = act_data['accel_z'].values[i: i + n_time_steps]\n",
    "\n",
    "            segments.append([xs, ys, zs])\n",
    "            labels.append(act)\n",
    "\n",
    "    #reshape the segments which is (list of arrays) to a list\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, n_time_steps, n_features)\n",
    "\n",
    "    labels = np.asarray(pd.get_dummies(labels), dtype = np.float32)\n",
    "    \n",
    "    return reshaped_segments,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def test_train_split(seg,labls):    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(seg, labls, test_size = 0.2, random_state = random_seed)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_LSTM(X_train,y_train):\n",
    "    model = Sequential()\n",
    "    # RNN layer\n",
    "    model.add(LSTM(units = 128, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "    # Dropout layer\n",
    "    model.add(Dropout(0.5)) \n",
    "    # Dense layer with ReLu\n",
    "    model.add(Dense(units = 64, activation='relu'))\n",
    "    # Softmax layer\n",
    "    model.add(Dense(y_train.shape[1], activation = 'softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cnn(trainX, trainy):\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=n_epochs, batch_size=batch_size, verbose=1)\n",
    "    # evaluate model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2951/2951 [==============================] - 19s 6ms/step - loss: 0.7012 - accuracy: 0.6946\n",
      "Epoch 2/20\n",
      "2951/2951 [==============================] - 18s 6ms/step - loss: 0.4909 - accuracy: 0.7969\n",
      "Epoch 3/20\n",
      "2951/2951 [==============================] - 18s 6ms/step - loss: 0.4259 - accuracy: 0.8238\n",
      "Epoch 4/20\n",
      "2951/2951 [==============================] - 18s 6ms/step - loss: 0.3836 - accuracy: 0.8423\n",
      "Epoch 5/20\n",
      "2951/2951 [==============================] - 20s 7ms/step - loss: 0.3489 - accuracy: 0.8591\n",
      "Epoch 6/20\n",
      "2951/2951 [==============================] - 21s 7ms/step - loss: 0.3218 - accuracy: 0.8690\n",
      "Epoch 7/20\n",
      "2951/2951 [==============================] - 20s 7ms/step - loss: 0.2989 - accuracy: 0.8788\n",
      "Epoch 8/20\n",
      "2951/2951 [==============================] - 20s 7ms/step - loss: 0.2815 - accuracy: 0.8868\n",
      "Epoch 9/20\n",
      "2951/2951 [==============================] - 19s 7ms/step - loss: 0.2694 - accuracy: 0.8915\n",
      "Epoch 10/20\n",
      "2951/2951 [==============================] - 17s 6ms/step - loss: 0.2552 - accuracy: 0.8974\n",
      "Epoch 11/20\n",
      "2951/2951 [==============================] - 17s 6ms/step - loss: 0.2402 - accuracy: 0.9039\n",
      "Epoch 12/20\n",
      "2951/2951 [==============================] - 17s 6ms/step - loss: 0.2336 - accuracy: 0.9063\n",
      "Epoch 13/20\n",
      "2951/2951 [==============================] - 18s 6ms/step - loss: 0.2253 - accuracy: 0.9098\n",
      "Epoch 14/20\n",
      "2951/2951 [==============================] - 20s 7ms/step - loss: 0.2156 - accuracy: 0.9139\n",
      "Epoch 15/20\n",
      "2951/2951 [==============================] - 21s 7ms/step - loss: 0.2093 - accuracy: 0.9160\n",
      "Epoch 16/20\n",
      "2951/2951 [==============================] - 22s 7ms/step - loss: 0.2020 - accuracy: 0.9199\n",
      "Epoch 17/20\n",
      "2951/2951 [==============================] - 23s 8ms/step - loss: 0.2011 - accuracy: 0.9199\n",
      "Epoch 18/20\n",
      "2951/2951 [==============================] - 25s 9ms/step - loss: 0.1900 - accuracy: 0.9247\n",
      "Epoch 19/20\n",
      "2951/2951 [==============================] - 25s 9ms/step - loss: 0.1852 - accuracy: 0.9263\n",
      "Epoch 20/20\n",
      "2951/2951 [==============================] - 25s 9ms/step - loss: 0.1808 - accuracy: 0.9281\n",
      "43/43 [==============================] - 1s 4ms/step - loss: 0.1870 - accuracy: 0.9384\n",
      "Test Accuracy (1): 0.9383712410926819\n",
      "Test Loss (1): 0.18700098991394043\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "for user in stationary_respiratory_df['user'].unique():\n",
    "    \n",
    "    train_df = stationary_respiratory_df[stationary_respiratory_df['user'] != user]\n",
    "    test_df = stationary_respiratory_df[stationary_respiratory_df['user'] == user]\n",
    "\n",
    "    X_train, y_train, categories = segments_overlap(train_df)\n",
    "    X_test, y_test, _ = segments_overlap(test_df)\n",
    "    \n",
    "    # model = model_LSTM(X_train,y_train)\n",
    "    # history = model.fit(X_train, y_train, epochs = n_epochs, validation_split = 0.20, batch_size = batch_size, verbose = 1)\n",
    "    \n",
    "    # print(f\"Test Accuracy ({user}):\", accuracy)\n",
    "    # print(f\"Test Loss ({user}):\", loss)\n",
    "    model  = model_cnn(X_train,y_train)\n",
    "    \n",
    "    \n",
    "    loss, accuracy = model.evaluate(X_test, y_test, batch_size = batch_size, verbose = 1)\n",
    "    print(f\"Test Accuracy ({user}):\", accuracy)\n",
    "    print(f\"Test Loss ({user}):\", loss)\n",
    "    \n",
    "    accuracies.append((user,loss,accuracy))\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8679383993148804"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, batch_size = batch_size, verbose = 1)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\chhal\\AppData\\Local\\Temp\\tmp2azeuqlj\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\chhal\\AppData\\Local\\Temp\\tmp2azeuqlj\\assets\n"
     ]
    }
   ],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open(f'../models/cnn_model_task{2}_{n_time_steps}_{n_features}.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['lyingBack breathingNormal', 'lyingBack coughing',\n",
       "        'lyingBack hyperventilating', 'lyingLeft breathingNormal',\n",
       "        'lyingLeft coughing', 'lyingLeft hyperventilating',\n",
       "        'lyingRight breathingNormal', 'lyingRight coughing',\n",
       "        'lyingRight hyperventilating', 'lyingStomach breathingNormal',\n",
       "        'lyingStomach coughing', 'lyingStomach hyperventilating',\n",
       "        'sitting_standing breathingNormal', 'sitting_standing coughing',\n",
       "        'sitting_standing hyperventilating'], dtype='<U33')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdiot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
